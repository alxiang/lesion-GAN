{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is to be used in conjunction with getPredictions (in the misc_scripts folder)\n",
    "\n",
    "After the weights of CNNs are collected and predictions evaluated into csv files with getPredictions, this notebook ensembles the csv predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metric\n",
    "from balancedAccuracy import balancedAccuracy\n",
    "num_classes = 3\n",
    "bacc_metric = balancedAccuracy(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot_confusion_matrix function\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [\"MEL\", \"NV\", \"BKL\"]\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(np.mean(np.diag(cm)))\n",
    "        \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    # get balanced accuracy\n",
    "    return np.mean(np.diag(cm))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data (for labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\".../3HAMAUG.npz\") # augmented HAM dataset with 3 classes numpy file\n",
    "\n",
    "targetValList = data[\"targetValList\"][:,:3]\n",
    "\n",
    "testData = np.load(\".../3TESTHAM.npz\")\n",
    "targetTestList = testData[\"targetTestList\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valMatrix(y_pred, save=False):\n",
    "    y_test = targetValList.copy()\n",
    "    y_test = y_test.argmax(1)\n",
    "    \n",
    "    if(len(y_pred.shape) != 1):\n",
    "        y_pred = y_pred.argmax(1)\n",
    "    \n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure()\n",
    "    print(\"Balanced Accuracy: \"+ str(plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                          title='Normalized Validation confusion matrix')))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testMatrix(y_pred, save=False):\n",
    "    y_test = targetTestList.copy()\n",
    "    y_test = y_test.argmax(1)\n",
    "    \n",
    "    if(len(y_pred.shape) != 1):\n",
    "        y_pred = y_pred.argmax(1)\n",
    "    \n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure()\n",
    "    print(\"Balanced Accuracy: \"+ str(plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                          title='Normalized Test Confusion Matrix')))\n",
    "    plt.tight_layout()\n",
    "    if(save): plt.savefig('testMatrix.png', dpi = 500)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: If using this file, fill in your own csv predictions and path\n",
    "\n",
    "PATH = \".../\"\n",
    "\n",
    "# using validation predicts\n",
    "vgg_pred = pd.read_csv(PATH+\"vgg16-validation.csv\",\n",
    "                      index_col=0)\n",
    "\n",
    "# using test predicts\n",
    "vgg_pred2 = pd.read_csv(PATH+\"vgg16-test.csv\",\n",
    "                          index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valMatrix(np.array(vgg_pred))\n",
    "testMatrix(np.array(vgg_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred_val = []\n",
    "\n",
    "for i in tqdm_notebook(vgg_pred.index):\n",
    "    avg_predict = np.average([vgg_pred\n",
    "                             \"\"\"\n",
    "                             other csv predictions here\n",
    "                             \n",
    "                             \"\"\" \n",
    "                              \n",
    "                             ]\n",
    "                             \n",
    "                             axis=0)\n",
    "    \n",
    "    avg_pred_val.append(avg_predict)\n",
    "    \n",
    "\n",
    "avg_pred_test = []\n",
    "\n",
    "for i in tqdm_notebook(vgg_pred2.index):\n",
    "    avg_predict = np.average([#vgg_pred2.iloc[i],\n",
    "                              \"\"\"\n",
    "                             other csv predictions here\n",
    "                             \n",
    "                             \"\"\" \n",
    "                              \n",
    "                                ]\n",
    "                             axis=0)\n",
    "    \n",
    "    avg_pred_test.append(avg_predict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valMatrix(np.array(avg_pred_val))\n",
    "testMatrix(np.array(avg_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF SVM Ensemble (train on validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_val_x = pd.concat([\"\"\"\n",
    "                        csv predictions here in list format\n",
    "\n",
    "                        \"\"\"], axis=1)\n",
    "svm_val_y = np.argmax(targetValList.copy(), axis=1)\n",
    "print(svm_val_x.shape, svm_val_y.shape)\n",
    "\n",
    "svm_test_x = pd.concat([\"\"\"\n",
    "                        csv predictions here in list format\n",
    "\n",
    "                        \"\"\"], axis=1)\n",
    "svm_test_y = np.argmax(targetTestList.copy(), axis=1)\n",
    "print(svm_test_x.shape, svm_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmEnsemble = SVC(C=.1, gamma=\"auto\", kernel=\"rbf\", class_weight=\"balanced\", random_state=8888)\n",
    "svmEnsemble = svmEnsemble.fit(svm_val_x, svm_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valMatrix(svmEnsemble.predict(svm_val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMatrix(svmEnsemble.predict(svm_test_x), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
