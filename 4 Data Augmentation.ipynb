{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN = pd.read_csv(\"Processed Images/TRAIN.csv\", index_col=0).drop(\"origin\", axis=1)\n",
    "\n",
    "# using modified TRAIN (4 classes dropped from 7-class dataset)\n",
    "TRAIN = pd.read_csv(\"Processed Images/TRAINmod.csv\", index_col=0)#.drop(\"origin\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MEL                                                     890\n",
       "NV                                                     5364\n",
       "BKL                                                     879\n",
       "origin    ISIC2018_Task3_Training_Input/ISIC2018_Task3_T...\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = TRAIN[TRAIN.origin==\"ISIC2018_Task3_Training_Input/\"]\n",
    "TRAIN.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into 5 folds for separate data augmentation and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(TRAIN.index)\n",
    "y = np.array(TRAIN)\n",
    "y = np.array([np.where(r==1)[0][0] for r in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=50, shuffle=True)\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)  \n",
    "\n",
    "\n",
    "foldList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in skf.split(X, y): # extract each fold one by one\n",
    "    foldList.append(X[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def cv2_clipped_zoom(img, zoom_factor):\n",
    "    \"\"\"\n",
    "    Center zoom in/out of the given image and returning an enlarged/shrinked view of \n",
    "    the image without changing dimensions\n",
    "    Args:\n",
    "        img : Image array\n",
    "        zoom_factor : amount of zoom as a ratio (0 to Inf)\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2] # It's also the final desired shape\n",
    "    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n",
    "\n",
    "    ### Crop only the part that will remain in the result (more efficient)\n",
    "    # Centered bbox of the final desired size in resized (larger/smaller) image coordinates\n",
    "    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n",
    "    y2, x2 = y1 + height, x1 + width\n",
    "    bbox = np.array([y1,x1,y2,x2])\n",
    "    # Map back to original image coordinates\n",
    "    bbox = (bbox / zoom_factor).astype(np.int)\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Handle padding when downscaling\n",
    "    resize_height, resize_width = min(new_height, height), min(new_width, width)\n",
    "    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) //2\n",
    "    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n",
    "    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n",
    "\n",
    "    result = cv2.resize(cropped_img, (resize_width, resize_height))\n",
    "    result = np.pad(result, pad_spec, mode='constant')\n",
    "    assert result.shape[0] == height and result.shape[1] == width\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to hold all image names and labels for augmented images\n",
    "AUGMENTED = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy import ndimage, misc\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "import imageio\n",
    "\n",
    "def augmentFold(foldNum, foldList):\n",
    "    for name in tqdm_notebook(foldList[foldNum]):\n",
    "        img = io.imread(\"Processed Images/TRAIN/\"+name+\".jpg\")\n",
    "\n",
    "        augs = [] # array of numpy array-images to be saved\n",
    "\n",
    "        # make i images per input image\n",
    "        for i in range(4):\n",
    "            newImg = ndimage.rotate(img, random.randint(1,3)*90) # rotate\n",
    "            \n",
    "            choice = random.randint(1,3) # flip\n",
    "            if(choice==2):\n",
    "                newImg = newImg[::-1, :, :]\n",
    "            elif(choice==3):\n",
    "                newImg = img[:, ::-1, :]\n",
    "                \n",
    "            # contrast and brightness augs, using Pillow (PIL fork)\n",
    "            newImg = Image.fromarray(newImg.astype('uint8'), 'RGB')\n",
    "            contrast = ImageEnhance.Contrast(newImg)\n",
    "            newImg = contrast.enhance(random.uniform(0.9,1.1))\n",
    "            brightness = ImageEnhance.Brightness(newImg)\n",
    "            newImg = np.array(brightness.enhance(random.uniform(0.9,1.1)))\n",
    "            newImg = cv2_clipped_zoom(newImg, random.uniform(0.9, 1))\n",
    "            augs.append(newImg)\n",
    "        \n",
    "        \n",
    "        # add to AUGMENTED dataframe and save images\n",
    "        label = np.array(TRAIN.loc[name]) # label for all augmented images from this \"name\"\n",
    "        for i in range(len(augs)):\n",
    "            AUGMENTED[name+\"_\"+str(i)] = label\n",
    "            imageio.imwrite(\"Processed Images/NEWTRAIN/FOLD\"+str(foldNum+1)+\"AUG/\"+name+\"_\"+str(i)+\".jpg\",\n",
    "                        augs[i])\n",
    "\n",
    "        # save original image in new separate folder\n",
    "        imageio.imwrite(\"Processed Images/NEWTRAIN/FOLD\"+str(foldNum+1)+\"/\"+name+\".jpg\",\n",
    "                    img)    \n",
    "\n",
    "    \n",
    "    return AUGMENTED.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_1_LABELS = augmentFold(0, foldList)\n",
    "FOLD_2_LABELS = augmentFold(1, foldList)\n",
    "FOLD_3_LABELS = augmentFold(2, foldList)\n",
    "FOLD_4_LABELS = augmentFold(3, foldList)\n",
    "FOLD_5_LABELS = augmentFold(4, foldList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTED.index = TRAIN.columns\n",
    "AUGMENTED.T.to_csv(\"Processed Images/NEWTRAIN/TRAINAUG.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTED.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTED.T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
